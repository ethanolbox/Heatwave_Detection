{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "import scipy, pandas as pd, numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "df = pd.read_csv(\"extracted_by_year/2006_extracted/2006tmax.csv\")\n",
    "df.head()\n",
    "\n",
    "# set the constants\n",
    "CUTOFF = 32.2\n",
    "DAYS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape, remove unnecessary columns and add statistical filter + threshold\n",
    "def proc(frame, upper_threshold, year):\n",
    "    processed = frame.copy()\n",
    "    for name in list(frame):\n",
    "        if name[:4] != \"tmax\" and name != \"GEOID20\":\n",
    "            processed = processed.drop(name, axis=1)\n",
    "    \n",
    "        \n",
    "    stats = processed.set_index('GEOID20')\n",
    "    stats = stats.apply(pd.DataFrame.describe, axis=1)\n",
    "    stats[\"upper\"] = stats[\"mean\"]+1.645*stats[\"std\"]\n",
    "\n",
    "    processed = processed.melt(id_vars='GEOID20', var_name='Date', value_name='Temp')\n",
    "    \n",
    "    # conversion to Python datetime objects\n",
    "    processed['Date'] = processed['Date'].map(lambda x: x.lstrip('tmax')) + str(year)\n",
    "    processed['Date'] = pd.to_datetime(processed['Date'], format='%b%d%Y')\n",
    "\n",
    "    # Set + sort by multi-level index using 'GEOID20' and 'Date'\n",
    "    processed.set_index(['GEOID20', 'Date'], inplace=True)\n",
    "    processed.sort_index(inplace=True)\n",
    "\n",
    "    thresholds = stats.copy()\n",
    "    thresholds.drop(columns=['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], inplace=True)\n",
    "    \n",
    "    # for upper here we currently have this as 32.2\n",
    "    thresholds['static']= upper_threshold\n",
    "    \n",
    "    merged = processed.reset_index().merge(thresholds.reset_index(), on='GEOID20', how='left').set_index(['GEOID20', 'Date'])\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create a (not indexed) boolean series which tells you whether an entry is part of a consecutive series of length n\n",
    "def consec_count_n(series, n):\n",
    "    temp = []\n",
    "    c = 0\n",
    "    for i in range(len(series.values)):\n",
    "        if series.values[i] == False:\n",
    "            c = 0\n",
    "        else:\n",
    "            c += 1\n",
    "        temp.append(c)\n",
    "    \n",
    "    result = []\n",
    "    pass_thres = False\n",
    "    for i in range(len(temp)):\n",
    "        if temp[-(i+1)] >= n:\n",
    "            pass_thres = True\n",
    "            result.append(True)\n",
    "        elif temp[-(i+1)] != 0 and pass_thres:\n",
    "            result.append(True)\n",
    "        else:\n",
    "            pass_thres = False\n",
    "            result.append(False)\n",
    "    result = result[::-1]\n",
    "\n",
    "    return pd.Series(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to check if the contig_mask (consec_count function) is working\n",
    "def check(frame, contig_mask):\n",
    "    threshold_mask = (frame['Temp'] > frame['upper']) | (frame['Temp'] > frame['static'])\n",
    "\n",
    "    result = pd.DataFrame(contig_mask)\n",
    "\n",
    "    result.reset_index()\n",
    "    result.columns = [\"contiguous\"]\n",
    "    result.index = frame.index\n",
    "\n",
    "    check = pd.DataFrame(result)\n",
    "    check.insert(1, \"true-false\", threshold_mask)\n",
    "    \n",
    "    with pd.option_context('display.max_rows', None,):\n",
    "        print(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which returns a filtered version of a given dataframe which only includes the entries which are part of a consecutive series of length n Trues for a boolean mask\n",
    "def consec_filter(frame, n):\n",
    "    threshold_mask = (frame['Temp'] > frame['upper']) | (frame['Temp'] > frame['static'])\n",
    "    \n",
    "    contig_mask = pd.DataFrame(data=consec_count_n(threshold_mask, n))\n",
    "\n",
    "    contig_mask.reset_index()\n",
    "    contig_mask.columns = [\"contiguous\"]\n",
    "    contig_mask.index = frame.index\n",
    "\n",
    "    filtered_data = frame[frame.index.isin(contig_mask.index[contig_mask['contiguous']])]\n",
    "\n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to turn the dataframe of days into flat data\n",
    "def flatten(frame):\n",
    "    sequences = []\n",
    "\n",
    "    # loop to find and append the sequences and their lengths to a new array\n",
    "    for zip_code, group in frame.groupby(level='GEOID20'):\n",
    "        start_date = None\n",
    "        sequence_length = 0\n",
    "        prev_date = None\n",
    "        for date in group.index.get_level_values('Date'):\n",
    "            if start_date is None:\n",
    "                start_date = date\n",
    "                sequence_length = 1\n",
    "            elif prev_date is not None and (date - prev_date).days == 1:\n",
    "                sequence_length += 1\n",
    "            else:\n",
    "                sequences.append({\n",
    "                    'GEOID20': zip_code,\n",
    "                    'Start_Date': start_date.date(),\n",
    "                    'Sequence_Length': sequence_length\n",
    "                })\n",
    "                start_date = date\n",
    "                sequence_length = 1\n",
    "            prev_date = date\n",
    "        if sequence_length > 0:\n",
    "            sequences.append({\n",
    "                'GEOID20': zip_code,\n",
    "                'Start_Date': start_date.date(),\n",
    "                'Sequence_Length': sequence_length\n",
    "            })\n",
    "    # flatten to 2d array\n",
    "    result = [[seq['GEOID20'], seq['Start_Date'], seq['Sequence_Length']] for seq in sequences]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to do the whole process for a single year\n",
    "def find_heatwaves(frame, cutoff, days, year):\n",
    "    processed = proc(frame, cutoff, year)\n",
    "    days = consec_filter(processed, days)\n",
    "    result = flatten(days)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Temp      upper  static\n",
      "GEOID20 Date                                \n",
      "1001    2006-01-01 -2.041  32.610467    32.2\n",
      "        2006-01-02 -0.211  32.610467    32.2\n",
      "        2006-01-03  3.070  32.610467    32.2\n",
      "        2006-01-04  1.140  32.610467    32.2\n",
      "        2006-01-05 -0.879  32.610467    32.2\n",
      "...                   ...        ...     ...\n",
      "99403   2006-12-27  5.746  34.555681    32.2\n",
      "        2006-12-28  5.304  34.555681    32.2\n",
      "        2006-12-29  2.147  34.555681    32.2\n",
      "        2006-12-30  2.066  34.555681    32.2\n",
      "        2006-12-31  2.168  34.555681    32.2\n",
      "\n",
      "[12154500 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "processed_2006 = proc(df, 32.2)\n",
    "print(processed_2006)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Temp      upper  static\n",
      "GEOID20 Date                                    \n",
      "1001    2006-07-17  34.178001  32.610467    32.2\n",
      "        2006-07-18  35.014000  32.610467    32.2\n",
      "        2006-07-19  35.320999  32.610467    32.2\n",
      "        2006-08-02  35.296001  32.610467    32.2\n",
      "        2006-08-03  37.244000  32.610467    32.2\n",
      "        2006-08-04  34.931000  32.610467    32.2\n",
      "1002    2006-07-17  33.160999  31.517748    32.2\n",
      "        2006-07-18  33.617001  31.517748    32.2\n",
      "        2006-07-19  33.664001  31.517748    32.2\n",
      "        2006-08-02  34.471001  31.517748    32.2\n",
      "        2006-08-03  35.634998  31.517748    32.2\n",
      "        2006-08-04  32.222000  31.517748    32.2\n"
     ]
    }
   ],
   "source": [
    "test_2 = consec_filter(processed_2006.loc[ 1001: 1002], 3)\n",
    "print(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1001, datetime.date(2006, 7, 17), 3], [1001, datetime.date(2006, 8, 2), 3], [1002, datetime.date(2006, 7, 17), 3], [1002, datetime.date(2006, 8, 2), 3]]\n"
     ]
    }
   ],
   "source": [
    "# Extract lengths of consecutive sequences\n",
    "testresult = flatten(test_2)\n",
    "\n",
    "print(testresult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export file\n",
    "np.savetxt(\"heatwave_instances_test.csv\", testresult, fmt='%s', delimiter=\", \", header=', '.join(['Zip_Code', 'Starting_Date', 'Days']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_2006 = consec_filter(processed_2006, 3)\n",
    "result_2006 = flatten(days_2006)\n",
    "\n",
    "#with pd.option_context('display.max_rows', None,):\n",
    "#    print(days_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the headers of the columns\n",
    "columnNames = ['Zip_Code', 'Starting_Date', 'Days']\n",
    "\n",
    "# export 2006\n",
    "np.savetxt(\"heatwave_2006_individual.csv\", result_2006, fmt='%s', delimiter=', ', header=', '.join(columnNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = range(2007, 2023)\n",
    "\n",
    "for year in years:\n",
    "    frame = pd.read_csv(\"extracted_by_year/\" + str(year) + \"_extracted/tmax\" + str(year) + \".csv\")\n",
    "    result = find_heatwaves(frame, CUTOFF, DAYS, year)\n",
    "    np.savetxt(\"heatwave_\" + str(year) + \".csv\", result, fmt='%s', delimiter=', ', header=', '.join(columnNames))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
